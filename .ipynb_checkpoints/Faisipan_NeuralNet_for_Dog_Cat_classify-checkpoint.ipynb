{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('catsvsdogs-train.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"images\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"labels\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('catsvsdogs-test.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"images\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"labels\"][:]) # your test set labels\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5000)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_y_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X to 2D array\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train_set_x_orig.flatten().reshape((len(train_set_x_orig),-1)) / 255, train_set_y_orig.T, test_size = 0.2, random_state = 42)\n",
    "X_test = test_set_x_orig.flatten().reshape((len(test_set_x_orig),-1)) / 255\n",
    "\n",
    "# Convert y to 1D array\n",
    "y_train = y_train.reshape(1, -1)\n",
    "y_validation = y_validation.reshape(1, -1)\n",
    "y_test = test_set_y_orig.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid_derivative(Z):\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = s * (1-s)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(Z):\n",
    "    return np.maximum(0, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu_derivative(Z):\n",
    "    temp = np.ones(Z.shape)\n",
    "    temp[Z<0] = 0\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(y, y_hat):\n",
    "    return np.sum((1./y.shape[1]) * (-np.multiply(y,np.log(y_hat)) - np.multiply(1-y, np.log(1-y_hat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Init_layer(X, y, num_layer = 3, num_node = 108, method='randn', random_state = 1):    \n",
    "    if random_state == 1:\n",
    "        np.random.seed(1)\n",
    "\n",
    "    param = {}\n",
    "    dims = []\n",
    "    dims.append(X.shape[1])\n",
    "    for i in range(num_layer):\n",
    "        dims.append(num_node)\n",
    "    dims.append(y.shape[0])\n",
    "\n",
    "    if method == 'randn':\n",
    "        for i in range(1, num_layer+2):\n",
    "            param['W'+str(i)] = np.random.randn(dims[i],dims[i-1]) / np.sqrt(dims[i-1]) \n",
    "            param['b'+str(i)] = np.random.randn(dims[i],1)                      \n",
    "    elif method == 'normal':\n",
    "        for i in range(1, num_layer+2):\n",
    "            param['W'+str(i)] = np.random.normal(0, 1/y.shape[1], (dims[i],dims[i-1])) \n",
    "            param['b'+str(i)] = np.ones((dims[i],1))   \n",
    "\n",
    "    return param, dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X, y, param, dims):\n",
    "    ch = {}\n",
    "    ch['A0'] = X.T\n",
    "    k = len(dims) - 1\n",
    "\n",
    "    for i in range(1, k+1):\n",
    "        Z = param['W'+str(i)].dot(ch['A'+str(i-1)]) + param['b'+str(i)] \n",
    "        if i == k:\n",
    "            A = Sigmoid(Z)\n",
    "        else:\n",
    "            A = Relu(Z)\n",
    "        ch['Z'+str(i)],ch['A'+str(i)]=Z,A\n",
    "\n",
    "    loss=Loss(y, ch['A'+str(k)])\n",
    "    return ch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(y, ch, param, dims, lr, regulization = None):\n",
    "    if regulization == 'l2':\n",
    "        regu = 1\n",
    "    else:\n",
    "        regu = 0\n",
    "    grad = {}\n",
    "    k = len(dims) - 1\n",
    "    m = y.shape[1]\n",
    "    for i in range(1, k+1)[::-1]:\n",
    "        if i == k:\n",
    "            e = (ch['A'+str(k)] - y) / m \n",
    "        else:\n",
    "            e = np.dot(param['W'+str(i+1)].T, grad['E'+str(i+1)]) * Relu_derivative(ch['Z'+str(i)])\n",
    "        grad['E'+str(i)] = e\n",
    "        grad['dW'+str(i)] = np.dot(e, ch['A'+str(i-1)].T) + 0.01 * param['W'+str(i)] * regu\n",
    "        grad['db'+str(i)] = np.sum(e)\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  1.9938894504470903\n",
      "accuracy score validation:  0.511\n",
      "accuracy score test:  0.49\n",
      "0.05\n",
      "iteration:  100  Loss:  0.6944525762087818\n",
      "accuracy score validation:  0.489\n",
      "accuracy score test:  0.51\n",
      "iteration:  200  Loss:  0.6925333231175099\n",
      "accuracy score validation:  0.493\n",
      "accuracy score test:  0.516\n",
      "iteration:  300  Loss:  0.6826650059042804\n",
      "accuracy score validation:  0.555\n",
      "accuracy score test:  0.566\n",
      "iteration:  400  Loss:  0.6798588196551001\n",
      "accuracy score validation:  0.552\n",
      "accuracy score test:  0.558\n",
      "iteration:  500  Loss:  0.6941153384029657\n",
      "accuracy score validation:  0.514\n",
      "accuracy score test:  0.536\n",
      "0.025\n",
      "iteration:  600  Loss:  0.6689219164105051\n",
      "accuracy score validation:  0.572\n",
      "accuracy score test:  0.574\n",
      "iteration:  700  Loss:  0.6707496574987832\n",
      "accuracy score validation:  0.588\n",
      "accuracy score test:  0.61\n",
      "iteration:  800  Loss:  0.6538746476675177\n",
      "accuracy score validation:  0.598\n",
      "accuracy score test:  0.61\n",
      "iteration:  900  Loss:  0.69019054959131\n",
      "accuracy score validation:  0.588\n",
      "accuracy score test:  0.574\n",
      "iteration:  1000  Loss:  0.6777574150774766\n",
      "accuracy score validation:  0.531\n",
      "accuracy score test:  0.548\n",
      "0.0125\n",
      "iteration:  1100  Loss:  0.6377950592526223\n",
      "accuracy score validation:  0.598\n",
      "accuracy score test:  0.62\n",
      "iteration:  1200  Loss:  0.6291618020332628\n",
      "accuracy score validation:  0.602\n",
      "accuracy score test:  0.626\n",
      "iteration:  1300  Loss:  0.6262896003036872\n",
      "accuracy score validation:  0.609\n",
      "accuracy score test:  0.632\n",
      "iteration:  1400  Loss:  0.6228192683532461\n",
      "accuracy score validation:  0.621\n",
      "accuracy score test:  0.622\n",
      "iteration:  1500  Loss:  0.6189969137336853\n",
      "accuracy score validation:  0.6\n",
      "accuracy score test:  0.602\n",
      "0.00625\n",
      "iteration:  1600  Loss:  0.6190583331532828\n",
      "accuracy score validation:  0.59\n",
      "accuracy score test:  0.618\n",
      "iteration:  1700  Loss:  0.6083196886457921\n",
      "accuracy score validation:  0.613\n",
      "accuracy score test:  0.628\n",
      "iteration:  1800  Loss:  0.6224516793605254\n",
      "accuracy score validation:  0.582\n",
      "accuracy score test:  0.598\n",
      "iteration:  1900  Loss:  0.5978746508340493\n",
      "accuracy score validation:  0.623\n",
      "accuracy score test:  0.628\n"
     ]
    }
   ],
   "source": [
    "# normal neural net\n",
    "\n",
    "iteration = 2000\n",
    "param, dims = Init_layer(X_train, y_train, 4, 35)\n",
    "lr = 0.1\n",
    "test_error = [1000]\n",
    "train_error = []\n",
    "k = len(dims) - 1\n",
    "for i in range(iteration):\n",
    "    mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "    X_batch = X_train[mini_batch, :]\n",
    "    y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "    ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "    grad = backward(y_batch, ch, param, dims, lr)\n",
    "        \n",
    "    for j in range(1, k+1):\n",
    "        param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "        param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "        print('iteration: ',i, ' Loss: ', J_train)\n",
    "    if i%100 == 0:\n",
    "        predicts = feed_forward(X_validation, y_validation, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5  \n",
    "        predicts_test = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "        print('accuracy score validation: ', accuracy_score(y_validation.T, predicts.T))    \n",
    "        print('accuracy score test: ', accuracy_score(y_test.T, predicts_test.T))       \n",
    "\n",
    "    if (i%500 == 0):\n",
    "        lr /= 2   \n",
    "        print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.5927351522329951\n",
      "accuracy score validation:  0.62\n",
      "accuracy score test:  0.612\n",
      "iteration:  100  Loss:  0.6546455481989716\n",
      "accuracy score validation:  0.556\n",
      "accuracy score test:  0.558\n",
      "iteration:  200  Loss:  0.6156413840588764\n",
      "accuracy score validation:  0.579\n",
      "accuracy score test:  0.574\n",
      "iteration:  300  Loss:  0.5894124436866046\n",
      "accuracy score validation:  0.597\n",
      "accuracy score test:  0.598\n",
      "iteration:  400  Loss:  0.5813653792594595\n",
      "accuracy score validation:  0.612\n",
      "accuracy score test:  0.606\n",
      "iteration:  500  Loss:  0.5762449187740519\n",
      "accuracy score validation:  0.615\n",
      "accuracy score test:  0.62\n",
      "0.003125\n",
      "iteration:  600  Loss:  0.5873580397455468\n",
      "accuracy score validation:  0.609\n",
      "accuracy score test:  0.626\n",
      "iteration:  700  Loss:  0.5590800686008373\n",
      "accuracy score validation:  0.618\n",
      "accuracy score test:  0.626\n",
      "iteration:  800  Loss:  0.5889452117860532\n",
      "accuracy score validation:  0.59\n",
      "accuracy score test:  0.584\n",
      "iteration:  900  Loss:  0.55876001955813\n",
      "accuracy score validation:  0.606\n",
      "accuracy score test:  0.638\n",
      "iteration:  1000  Loss:  0.5477372586617598\n",
      "accuracy score validation:  0.621\n",
      "accuracy score test:  0.618\n",
      "0.0015625\n",
      "iteration:  1100  Loss:  0.5409357014068913\n",
      "accuracy score validation:  0.62\n",
      "accuracy score test:  0.614\n",
      "iteration:  1200  Loss:  0.5448288420693692\n",
      "accuracy score validation:  0.612\n",
      "accuracy score test:  0.628\n"
     ]
    }
   ],
   "source": [
    "for i in range(iteration):\n",
    "    mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "    X_batch = X_train[mini_batch, :]\n",
    "    y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "    ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "    grad = backward(y_batch, ch, param, dims, lr)\n",
    "        \n",
    "    for j in range(1, k+1):\n",
    "        param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "        param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "        print('iteration: ',i, ' Loss: ', J_train)\n",
    "    if i%100 == 0:\n",
    "        predicts = feed_forward(X_validation, y_validation, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5  \n",
    "        predicts_test = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "        print('accuracy score validation: ', accuracy_score(y_validation.T, predicts.T))    \n",
    "        print('accuracy score test: ', accuracy_score(y_test.T, predicts_test.T))       \n",
    "\n",
    "    if ((i%500 == 0) & (i>1)):\n",
    "        lr /= 2   \n",
    "        print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.6126793293249149\n",
      "accuracy score validation:  0.605\n",
      "accuracy score test:  0.614\n",
      "0.0015625\n",
      "iteration:  100  Loss:  0.6161912234125029\n",
      "accuracy score validation:  0.588\n",
      "accuracy score test:  0.616\n",
      "iteration:  200  Loss:  0.6076229628920211\n",
      "accuracy score validation:  0.595\n",
      "accuracy score test:  0.628\n",
      "iteration:  300  Loss:  0.6062038001760329\n",
      "accuracy score validation:  0.605\n",
      "accuracy score test:  0.622\n",
      "iteration:  400  Loss:  0.6086605069199281\n",
      "accuracy score validation:  0.598\n",
      "accuracy score test:  0.62\n",
      "0.00078125\n",
      "iteration:  500  Loss:  0.6056425787115369\n",
      "accuracy score validation:  0.609\n",
      "accuracy score test:  0.612\n",
      "iteration:  600  Loss:  0.6046704309278774\n",
      "accuracy score validation:  0.607\n",
      "accuracy score test:  0.638\n",
      "iteration:  700  Loss:  0.6011355178182889\n",
      "accuracy score validation:  0.603\n",
      "accuracy score test:  0.624\n",
      "iteration:  800  Loss:  0.6006937856118263\n",
      "accuracy score validation:  0.602\n",
      "accuracy score test:  0.616\n",
      "0.000390625\n",
      "iteration:  900  Loss:  0.5995361791472739\n",
      "accuracy score validation:  0.607\n",
      "accuracy score test:  0.638\n",
      "iteration:  1000  Loss:  0.5990505408128677\n",
      "accuracy score validation:  0.602\n",
      "accuracy score test:  0.634\n",
      "iteration:  1100  Loss:  0.5985982917542909\n",
      "accuracy score validation:  0.606\n",
      "accuracy score test:  0.624\n",
      "iteration:  1200  Loss:  0.5978785430817446\n",
      "accuracy score validation:  0.597\n",
      "accuracy score test:  0.638\n",
      "0.0001953125\n",
      "iteration:  1300  Loss:  0.5976295433198776\n",
      "accuracy score validation:  0.599\n",
      "accuracy score test:  0.636\n",
      "iteration:  1400  Loss:  0.5974783761384116\n",
      "accuracy score validation:  0.603\n",
      "accuracy score test:  0.632\n",
      "iteration:  1500  Loss:  0.597387328406484\n",
      "accuracy score validation:  0.601\n",
      "accuracy score test:  0.648\n",
      "iteration:  1600  Loss:  0.5968880049647936\n",
      "accuracy score validation:  0.603\n",
      "accuracy score test:  0.634\n",
      "9.765625e-05\n",
      "iteration:  1700  Loss:  0.5970904937386938\n",
      "accuracy score validation:  0.6\n",
      "accuracy score test:  0.626\n",
      "iteration:  1800  Loss:  0.59689047859036\n",
      "accuracy score validation:  0.601\n",
      "accuracy score test:  0.644\n",
      "iteration:  1900  Loss:  0.5964095380761703\n",
      "accuracy score validation:  0.596\n",
      "accuracy score test:  0.638\n"
     ]
    }
   ],
   "source": [
    "for i in range(iteration):\n",
    "    mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "    X_batch = X_train[mini_batch, :]\n",
    "    y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "    ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "    grad = backward(y_batch, ch, param, dims, lr)\n",
    "        \n",
    "    for j in range(1, k+1):\n",
    "        param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "        param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "        print('iteration: ',i, ' Loss: ', J_train)\n",
    "    if i%100 == 0:\n",
    "        predicts = feed_forward(X_validation, y_validation, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5  \n",
    "        predicts_test = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "        print('accuracy score validation: ', accuracy_score(y_validation.T, predicts.T))    \n",
    "        print('accuracy score test: ', accuracy_score(y_test.T, predicts_test.T))       \n",
    "\n",
    "    if (i%500 == 0):\n",
    "        lr /= 2   \n",
    "        print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.5936369442085235\n",
      "accuracy score validation:  0.602\n",
      "accuracy score test:  0.644\n",
      "4.8828125e-05\n",
      "iteration:  100  Loss:  0.5933838803694436\n",
      "accuracy score validation:  0.609\n",
      "accuracy score test:  0.636\n",
      "iteration:  200  Loss:  0.5932685450790218\n",
      "accuracy score validation:  0.608\n",
      "accuracy score test:  0.64\n",
      "iteration:  300  Loss:  0.5932768925173137\n",
      "accuracy score validation:  0.606\n",
      "accuracy score test:  0.638\n",
      "iteration:  400  Loss:  0.5933758797952782\n",
      "accuracy score validation:  0.603\n",
      "accuracy score test:  0.636\n",
      "2.44140625e-05\n",
      "iteration:  500  Loss:  0.5931016846822831\n",
      "accuracy score validation:  0.609\n",
      "accuracy score test:  0.64\n",
      "iteration:  600  Loss:  0.5930781883456697\n",
      "accuracy score validation:  0.607\n",
      "accuracy score test:  0.638\n",
      "iteration:  700  Loss:  0.5930002308161553\n",
      "accuracy score validation:  0.606\n",
      "accuracy score test:  0.642\n",
      "iteration:  800  Loss:  0.592970509655866\n",
      "accuracy score validation:  0.606\n",
      "accuracy score test:  0.64\n",
      "iteration:  900  Loss:  0.5929524343487893\n",
      "accuracy score validation:  0.608\n",
      "accuracy score test:  0.642\n",
      "iteration:  1000  Loss:  0.5929072587195722\n",
      "accuracy score validation:  0.608\n",
      "accuracy score test:  0.64\n",
      "iteration:  1100  Loss:  0.5928576256541838\n",
      "accuracy score validation:  0.605\n",
      "accuracy score test:  0.642\n",
      "iteration:  1200  Loss:  0.5928455701224662\n",
      "accuracy score validation:  0.607\n",
      "accuracy score test:  0.644\n",
      "iteration:  1300  Loss:  0.5927969763608516\n",
      "accuracy score validation:  0.607\n",
      "accuracy score test:  0.64\n",
      "iteration:  1400  Loss:  0.5927581721568753\n",
      "accuracy score validation:  0.608\n",
      "accuracy score test:  0.64\n",
      "iteration:  1500  Loss:  0.592769696619394\n",
      "accuracy score validation:  0.608\n",
      "accuracy score test:  0.638\n",
      "iteration:  1600  Loss:  0.5926777356107735\n",
      "accuracy score validation:  0.607\n",
      "accuracy score test:  0.64\n",
      "iteration:  1700  Loss:  0.5926615736229665\n",
      "accuracy score validation:  0.606\n",
      "accuracy score test:  0.64\n",
      "iteration:  1800  Loss:  0.5926592808387695\n",
      "accuracy score validation:  0.603\n",
      "accuracy score test:  0.644\n",
      "iteration:  1900  Loss:  0.5926076412283519\n",
      "accuracy score validation:  0.606\n",
      "accuracy score test:  0.646\n"
     ]
    }
   ],
   "source": [
    "for i in range(iteration):\n",
    "    mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "    X_batch = X_train[mini_batch, :]\n",
    "    y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "    ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "    grad = backward(y_batch, ch, param, dims, lr)\n",
    "        \n",
    "    for j in range(1, k+1):\n",
    "        param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "        param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "        print('iteration: ',i, ' Loss: ', J_train)\n",
    "    if i%100 == 0:\n",
    "        predicts = feed_forward(X_validation, y_validation, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5  \n",
    "        predicts_test = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "        print('accuracy score validation: ', accuracy_score(y_validation.T, predicts.T))    \n",
    "        print('accuracy score test: ', accuracy_score(y_test.T, predicts_test.T))       \n",
    "\n",
    "    if ((i%400 == 0) & (lr > 0.00003)):\n",
    "        lr /= 2   \n",
    "        print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.5452434182862218\n",
      "accuracy score validation:  0.632\n",
      "accuracy score test:  0.652\n",
      "iteration:  100  Loss:  0.545183132067119\n",
      "accuracy score validation:  0.635\n",
      "accuracy score test:  0.65\n",
      "iteration:  200  Loss:  0.5452125587998857\n",
      "accuracy score validation:  0.636\n",
      "accuracy score test:  0.658\n",
      "iteration:  300  Loss:  0.5449398988546333\n",
      "accuracy score validation:  0.633\n",
      "accuracy score test:  0.65\n",
      "iteration:  400  Loss:  0.5448683650385318\n",
      "accuracy score validation:  0.636\n",
      "accuracy score test:  0.652\n",
      "iteration:  500  Loss:  0.5446528355866211\n",
      "accuracy score validation:  0.631\n",
      "accuracy score test:  0.652\n",
      "iteration:  600  Loss:  0.5446290090049842\n",
      "accuracy score validation:  0.634\n",
      "accuracy score test:  0.65\n",
      "iteration:  700  Loss:  0.5444459603127434\n",
      "accuracy score validation:  0.63\n",
      "accuracy score test:  0.65\n",
      "iteration:  800  Loss:  0.544603619128703\n",
      "accuracy score validation:  0.635\n",
      "accuracy score test:  0.654\n",
      "iteration:  900  Loss:  0.5441866252434995\n",
      "accuracy score validation:  0.63\n",
      "accuracy score test:  0.65\n",
      "iteration:  1000  Loss:  0.5443037203583829\n",
      "accuracy score validation:  0.634\n",
      "accuracy score test:  0.656\n",
      "iteration:  1100  Loss:  0.5440065868689865\n",
      "accuracy score validation:  0.633\n",
      "accuracy score test:  0.654\n",
      "iteration:  1200  Loss:  0.5438822323435524\n",
      "accuracy score validation:  0.633\n",
      "accuracy score test:  0.652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-8128b1c28d98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(iteration):\n",
    "    mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "    X_batch = X_train[mini_batch, :]\n",
    "    y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "    ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "    grad = backward(y_batch, ch, param, dims, lr)\n",
    "        \n",
    "    for j in range(1, k+1):\n",
    "        param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "        param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "        print('iteration: ',i, ' Loss: ', J_train)\n",
    "    if i%100 == 0:\n",
    "        predicts = feed_forward(X_validation, y_validation, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5  \n",
    "        predicts_test = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "        print('accuracy score validation: ', accuracy_score(y_validation.T, predicts.T))    \n",
    "        print('accuracy score test: ', accuracy_score(y_test.T, predicts_test.T)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.6955095821083643\n",
      "accuracy score:  0.49\n",
      "iteration:  100  Loss:  0.6941612657646118\n",
      "accuracy score:  0.51\n",
      "iteration:  200  Loss:  0.6948577463266178\n",
      "accuracy score:  0.49\n",
      "iteration:  300  Loss:  0.6931529473043672\n",
      "accuracy score:  0.51\n",
      "iteration:  400  Loss:  0.695208482255957\n",
      "accuracy score:  0.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-402aa3af59aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dW'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# init W with normal distribution\n",
    "\n",
    "iteration = 2000\n",
    "param, dims = Init_layer(X_train, y_train, 4, 35, method='normal')\n",
    "lr = 0.05\n",
    "test_error = [1000]\n",
    "train_error = []\n",
    "k = len(dims) - 1\n",
    "for i in range(iteration):\n",
    "    mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "    X_batch = X_train[mini_batch, :]\n",
    "    y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "    ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "    grad = backward(y_batch, ch, param, dims, lr)\n",
    "        \n",
    "    for j in range(1, k+1):\n",
    "        param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "        param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "        print('iteration: ',i, ' Loss: ', J_train)\n",
    "    if i%100 == 0:\n",
    "        predicts = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "        print('accuracy score: ', accuracy_score(y_test.T, predicts.T))       \n",
    "    if ((i%300==0) & (i < 2100)):\n",
    "        lr /= 2        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 49152)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param['W1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.8871804176405083\n",
      "accuracy score:  0.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-e2732b18cca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mvb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mvt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'V'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'V'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dW'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mvb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mvt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'V'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Nesterov \n",
    "\n",
    "iteration = 2000\n",
    "param, dims = Init_layer(X_train, y_train, 4, 35)\n",
    "param_pre = {}\n",
    "lr = 0.003\n",
    "test_error = [1000]\n",
    "train_error = []\n",
    "k = len(dims) - 1\n",
    "vt, vb = {}, {}\n",
    "\n",
    "for i in range(iteration):\n",
    "    mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "    X_batch = X_train[mini_batch, :]\n",
    "    y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "    ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "    grad = backward(y_batch, ch, param, dims, lr)\n",
    " \n",
    "    for j in range(1, k+1):\n",
    "        param_pre['W'+str(j)] = param['W'+str(j)] - lr * grad['dW'+str(j)]\n",
    "        param_pre['b'+str(j)] = param['b'+str(j)] - lr * grad['db'+str(j)]   \n",
    "        \n",
    "    ch_pre, loss_pre = feed_forward(X_batch, y_batch, param_pre, dims)\n",
    "    grad_pre = backward(y_batch, ch_pre, param_pre, dims, lr)\n",
    "    \n",
    "    for j in range(1, k+1):\n",
    "        if i == 0:\n",
    "            vt['V'+str(j)] = lr * grad_pre['dW'+str(j)]\n",
    "            vb['b'+str(j)] = lr * grad_pre['db'+str(j)]\n",
    "        else:\n",
    "            vt['V'+str(j)] = 0.9*vt['V'+str(j)] + lr * grad_pre['dW'+str(j)]\n",
    "            vb['b'+str(j)] = 0.9*vb['b'+str(j)] + lr * grad_pre['db'+str(j)]\n",
    "        param['W'+str(j)] -= vt['V'+str(j)]\n",
    "        param['b'+str(j)] -= vb['b'+str(j)]\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "        print('iteration: ',i, ' Loss: ', J_train)\n",
    "    if i%100 == 0:\n",
    "        predicts = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "        print('accuracy score: ', accuracy_score(y_test.T, predicts.T))       \n",
    "    if ((i%300==0) & (i < 2100)):\n",
    "        lr /= 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.9704499954256084\n",
      "accuracy score:  0.51\n",
      "iteration:  100  Loss:  0.5974081422903474\n",
      "accuracy score:  0.592\n",
      "iteration:  200  Loss:  0.5273934843292094\n",
      "accuracy score:  0.622\n",
      "iteration:  300  Loss:  0.4641967823611979\n",
      "accuracy score:  0.618\n",
      "iteration:  400  Loss:  0.3676355282946672\n",
      "accuracy score:  0.624\n",
      "iteration:  500  Loss:  0.31023648415954586\n",
      "accuracy score:  0.604\n",
      "iteration:  600  Loss:  0.24018278939045262\n",
      "accuracy score:  0.608\n",
      "iteration:  700  Loss:  0.1663220202829015\n",
      "accuracy score:  0.61\n",
      "iteration:  800  Loss:  0.14359585109620937\n",
      "accuracy score:  0.644\n",
      "iteration:  900  Loss:  0.10208230017430005\n",
      "accuracy score:  0.628\n",
      "iteration:  1000  Loss:  0.08094159644830227\n",
      "accuracy score:  0.638\n",
      "iteration:  1100  Loss:  0.07172721464890514\n",
      "accuracy score:  0.624\n",
      "iteration:  1200  Loss:  0.057891172865939367\n",
      "accuracy score:  0.62\n",
      "iteration:  1300  Loss:  0.04956170070121617\n",
      "accuracy score:  0.624\n",
      "iteration:  1400  Loss:  0.04648986230826758\n",
      "accuracy score:  0.632\n",
      "iteration:  1500  Loss:  0.04392432138414247\n",
      "accuracy score:  0.642\n",
      "iteration:  1600  Loss:  0.0417415278524789\n",
      "accuracy score:  0.638\n",
      "iteration:  1700  Loss:  0.03940511695035037\n",
      "accuracy score:  0.628\n",
      "iteration:  1800  Loss:  0.03891155621990006\n",
      "accuracy score:  0.634\n",
      "iteration:  1900  Loss:  0.03733292426986723\n",
      "accuracy score:  0.632\n",
      "iteration:  2000  Loss:  0.03661312242106582\n",
      "accuracy score:  0.632\n",
      "iteration:  2100  Loss:  0.03600859591316587\n",
      "accuracy score:  0.638\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-3f5d8e583e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mch_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mgrad_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-e49e7b99eadc>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(y, ch, param, dims, lr)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'E'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mRelu_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Z'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'E'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dW'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.01\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Nesterov with standardscaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_scale = StandardScaler().fit_transform(X_train)\n",
    "X_test_scale = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "iteration = 3000\n",
    "param, dims = Init_layer(X_train, y_train, 4, 35)\n",
    "param_pre = {}\n",
    "lr = 0.003\n",
    "test_error = [1000]\n",
    "train_error = []\n",
    "k = len(dims) - 1\n",
    "vt, vb = {}, {}\n",
    "\n",
    "for i in range(iteration):\n",
    "    mini_batch = np.random.randint(0, X_train_scale.shape[0], 64)\n",
    "    X_batch = X_train_scale[mini_batch, :]\n",
    "    y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "    ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "    grad = backward(y_batch, ch, param, dims, lr)\n",
    " \n",
    "    for j in range(1, k+1):\n",
    "        param_pre['W'+str(j)] = param['W'+str(j)] - lr * grad['dW'+str(j)]\n",
    "        param_pre['b'+str(j)] = param['b'+str(j)] - lr * grad['db'+str(j)]   \n",
    "        \n",
    "    ch_pre, loss_pre = feed_forward(X_batch, y_batch, param_pre, dims)\n",
    "    grad_pre = backward(y_batch, ch_pre, param_pre, dims, lr)\n",
    "    \n",
    "    for j in range(1, k+1):\n",
    "        if i == 0:\n",
    "            vt['V'+str(j)] = lr * grad_pre['dW'+str(j)]\n",
    "            vb['b'+str(j)] = lr * grad_pre['db'+str(j)]\n",
    "        else:\n",
    "            vt['V'+str(j)] = 0.9*vt['V'+str(j)] + lr * grad_pre['dW'+str(j)]\n",
    "            vb['b'+str(j)] = 0.9*vb['b'+str(j)] + lr * grad_pre['db'+str(j)]\n",
    "        param['W'+str(j)] -= vt['V'+str(j)]\n",
    "        param['b'+str(j)] -= vb['b'+str(j)]\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        J_train = feed_forward(X_train_scale, y_train, param, dims)[1]\n",
    "        print('iteration: ',i, ' Loss: ', J_train)\n",
    "    if i%100 == 0:\n",
    "        predicts = feed_forward(X_test_scale, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "        print('accuracy score: ', accuracy_score(y_test.T, predicts.T))       \n",
    "    if ((i%300==0) & (i < 2100)):\n",
    "        lr /= 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.7610668796365103\n",
      "accuracy score:  0.51\n",
      "iteration:  0  Loss:  0.7610668796365103\n",
      "accuracy score:  0.51\n",
      "iteration:  0  Loss:  0.7610668796365103\n",
      "accuracy score:  0.51\n",
      "iteration:  0  Loss:  0.7610668796365103\n",
      "accuracy score:  0.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-f5841b303e46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mJ_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iteration: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' Loss: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-bcd94e10e34e>\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(X, y, param, dims)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# gradient bossting\n",
    "\n",
    "lr = 0.005\n",
    "k = len(dims) - 1\n",
    "X_train_gra = X_train\n",
    "y_train_gra = y_train\n",
    "model_param = {}\n",
    "model_predict = np.zeros((1, y_test.shape[1]))\n",
    "\n",
    "for num_tree in range(1,10):\n",
    "    param, dims = Init_layer(X_train, y_train, 4, 35)\n",
    "\n",
    "    for i in range(10):\n",
    "        mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "        X_batch = X_train_gra[mini_batch, :]\n",
    "        y_batch = y_train_gra[0, mini_batch].reshape(1, -1)\n",
    "        ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "        grad = backward(y_batch, ch, param, dims, lr)\n",
    "        \n",
    "        for j in range(1, k+1):\n",
    "            param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "            param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "            print('iteration: ',i, ' Loss: ', J_train)\n",
    "        if i%100 == 0:\n",
    "            predicts = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "    \n",
    "    model_param[str(num_tree)+'model'] = param\n",
    "    predict_train = feed_forward(X_train_gra, y_train_gra, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5 \n",
    "    model_predict += predicts\n",
    "    print('accuracy score: ', accuracy_score(y_test.T, model_predict.T))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23866094262372387\n",
      "accuracy score:  0.51\n",
      "0.30613918040231886\n",
      "accuracy score:  0.51\n",
      "[[False False False ... False False False]]\n",
      "0.23866094262372387\n",
      "accuracy score:  0.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-c5199cf9f342>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train_gra\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-e49e7b99eadc>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(y, ch, param, dims, lr)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'E'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mRelu_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Z'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'E'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dW'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.01\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'db'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration = 200\n",
    "test_error = [1000]\n",
    "train_error = []\n",
    "k = len(dims) - 1\n",
    "all_model_prediction = np.zeros((1, y_test.shape[1]))\n",
    "X_train_gra = X_train\n",
    "y_train_gra = y_train\n",
    "\n",
    "for num_model in range(2):\n",
    "    lr = 0.05\n",
    "    param, dims = Init_layer(X_train_gra, y_train_gra, 4, 35)\n",
    "    for i in range(101):\n",
    "        mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "        X_batch = X_train_gra[mini_batch, :]\n",
    "        y_batch = y_train_gra[0, mini_batch].reshape(1, -1)\n",
    "        ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "        grad = backward(y_batch, ch, param, dims, lr)\n",
    "\n",
    "        for j in range(1, k+1):\n",
    "            param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "            param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print(feed_forward(X_train_gra, y_train_gra, param, dims)[1])\n",
    "            predicts = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "            print('accuracy score: ', accuracy_score(y_test.T, predicts.T))       \n",
    "        if (((i%200==0) & (i < 1000)) | ((i%500==0) & (i > 0.0001))):\n",
    "            lr /= 2  \n",
    "    y_train_predict = feed_forward(X_train_gra, y_train_gra, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5 \n",
    "    print(y_train_predict)\n",
    "    y_test_predict = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5 \n",
    "    y_train_gra -= y_train_predict\n",
    "    all_model_prediction += y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  Loss:  0.7637806535320173\n",
      "accuracy score:  0.49\n",
      "iteration:  100  Loss:  0.6887826298440516\n",
      "accuracy score:  0.534\n",
      "iteration:  200  Loss:  0.6817449639844069\n",
      "accuracy score:  0.554\n",
      "iteration:  300  Loss:  0.6782380934493155\n",
      "accuracy score:  0.548\n",
      "iteration:  400  Loss:  0.6642642021853835\n",
      "accuracy score:  0.62\n",
      "iteration:  0  Loss:  0.13350048979445994\n",
      "accuracy score:  0.51\n",
      "iteration:  100  Loss:  0.03332931646988882\n",
      "accuracy score:  0.51\n",
      "iteration:  200  Loss:  0.031557945135830184\n",
      "accuracy score:  0.51\n",
      "iteration:  300  Loss:  0.09343441667893834\n",
      "accuracy score:  0.51\n",
      "iteration:  400  Loss:  0.09150456184566605\n",
      "accuracy score:  0.51\n",
      "iteration:  0  Loss:  0.13350048979445994\n",
      "accuracy score:  0.51\n",
      "iteration:  100  Loss:  0.03332931646988882\n",
      "accuracy score:  0.51\n",
      "iteration:  200  Loss:  0.031557945135830184\n",
      "accuracy score:  0.51\n",
      "iteration:  300  Loss:  0.09343441667893834\n",
      "accuracy score:  0.51\n",
      "iteration:  400  Loss:  0.09150456184566605\n",
      "accuracy score:  0.51\n"
     ]
    }
   ],
   "source": [
    "iteration = 500\n",
    "lr = 0.05\n",
    "test_error = [1000]\n",
    "train_error = []\n",
    "k = len(dims) - 1\n",
    "all_predict = np.zeros((1, y_test.shape[1]))\n",
    "for num in range(3):\n",
    "    param, dims = Init_layer(X_train, y_train, 4, 35)\n",
    "    lr = 0.05\n",
    "    for i in range(iteration):\n",
    "        mini_batch = np.random.randint(0, X_train.shape[0], 64)\n",
    "        X_batch = X_train[mini_batch, :]\n",
    "        y_batch = y_train[0, mini_batch].reshape(1, -1)\n",
    "        ch, loss = feed_forward(X_batch, y_batch, param, dims)\n",
    "        grad = backward(y_batch, ch, param, dims, lr)\n",
    "\n",
    "        for j in range(1, k+1):\n",
    "            param['W'+str(j)] -= lr * grad['dW'+str(j)]\n",
    "            param['b'+str(j)] -= lr * grad['db'+str(j)]\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            J_train = feed_forward(X_train, y_train, param, dims)[1]\n",
    "            print('iteration: ',i, ' Loss: ', J_train)\n",
    "        if i%100 == 0:\n",
    "            predicts = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5   \n",
    "            print('accuracy score: ', accuracy_score(y_test.T, predicts.T))       \n",
    "        if (((i%200==0) & (i < 1000)) | ((i%500==0) & (i > 0.0001))):\n",
    "            lr /= 2        \n",
    "\n",
    "    y_train_predict = feed_forward(X_train, y_train, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5  \n",
    "    y_train -= y_train_predict\n",
    "    y_test_predict = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5  \n",
    "    all_predict += y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.616"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.T, all_predict.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicts = feed_forward(X_test, y_test, param, dims)[0]['A'+str(len(dims)-1)] >= 0.5\n",
    "print('accuracy score: ', accuracy_score(y_test.T, predicts.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
